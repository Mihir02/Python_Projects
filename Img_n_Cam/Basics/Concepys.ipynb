{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Image and Video Processing with Python"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import cv2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "OpenCV is basically a library for **Computer Vision** in python.\r\n",
    "## Loading, Displaying, Resizing and Creating Images\r\n",
    "\r\n",
    "`cv2.imread()` takes, along with file location, a parameter that expects $0$ , $1$ or $-1$.\r\n",
    "\r\n",
    "$0$ = black and white or grayscales\r\n",
    "\r\n",
    "$1$ = rbg image (Yes, python follows *rbg* instead of *rgb*, as if there wasn't enough idiotics)\r\n",
    "\r\n",
    "$-1$ = Color image with *alpha* channel which controls transparency.\r\n",
    "### Opening images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "img = cv2.imread(\"..\\Files\\galaxy.jpg\", 0)\r\n",
    "print(\"Dimensions = \",img.ndim)\r\n",
    "print(img)  \r\n",
    "print(type(img))\r\n",
    "print(img.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dimensions =  2\n",
      "[[14 18 14 ... 20 15 16]\n",
      " [12 16 12 ... 20 15 17]\n",
      " [12 13 16 ... 14 24 21]\n",
      " ...\n",
      " [ 0  0  0 ...  5  8 14]\n",
      " [ 0  0  0 ...  2  3  9]\n",
      " [ 1  1  1 ...  1  1  3]]\n",
      "<class 'numpy.ndarray'>\n",
      "(1485, 990)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So this is a `2-D` matrix, *ndarray* to be precise. And it has a resolution of $1485 X 990$ "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "img_c = cv2.imread(\"..\\Files\\galaxy.jpg\", 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Displaying Images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "cv2.imshow(\"Galaxy\", img)\r\n",
    "cv2.waitKey(2000)    #Time for the window to close. 0 = close on press of any button\r\n",
    "cv2.destroyAllWindows()   #What to do after the aforementioned time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "See it was closed after 2 secs.\r\n",
    "\r\n",
    "Now we need to resize the image so that it may fit our screen (or whatever your reason is for resizing.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Resizing images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "resized_img = cv2.resize(img, (1920, 1080))\r\n",
    "cv2.imshow(\"Galaxy\", resized_img)\r\n",
    "cv2.waitKey(0)    #Time for the window to close. 0 = close on press of any button\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "See, it was resized. What is happening here is that *python* is resizing the numpy array. It takes the array and creates a new array of required shape by interpolating new data to fit the new size. It does a good job though the expected wierdness like streatching effect will creep into the image.\r\n",
    "\r\n",
    "\r\n",
    "To maintain the aspect ration of the image, we can do this:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "resized_immg_2 = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))\r\n",
    "cv2.imshow(\"Galaxy_resized\", resized_immg_2)\r\n",
    "cv2.waitKey(0)    #Time for the window to close. 0 = close on press of any button\r\n",
    "cv2.destroyAllWindows()\r\n",
    "print(resized_immg_2.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(742, 495)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So that halved the size (and resolution)\r\n",
    "\r\n",
    "### Writing images (Saving)\r\n",
    "As expected the method for this is **`imwrite()`** method"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "cv2.imwrite(\"..\\Files\\P_Galaxy_resized.jpg\", resized_immg_2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Batch image resizing\r\n",
    "To batch processing, we need to create a list containing the image file paths. Then we can easily iterate over it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "\r\n",
    "import glob  # Finds path names given a certain patterns\r\n",
    "\r\n",
    "images= glob.glob(r\"..\\Files\\*.jpg\")\r\n",
    "i = 0\r\n",
    "for image in images:\r\n",
    "    img=cv2.imread(image,0)\r\n",
    "    re=cv2.resize(img,(200,200))\r\n",
    "    cv2.imshow(\"Hey\",re)\r\n",
    "    cv2.waitKey(10)\r\n",
    "    cv2.destroyAllWindows()\r\n",
    "    print(cv2.imwrite(r\"..\\Files\\Batch_res_ex\\resized_\"+str(i)+\".jpg\",re), image)\r\n",
    "    i += 1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True ..\\Files\\galaxy.jpg\n",
      "True ..\\Files\\kangaroos-rain-australia_71370_990x742.jpg\n",
      "True ..\\Files\\Lighthouse.jpg\n",
      "True ..\\Files\\Moon sinking, sun rising.jpg\n",
      "True ..\\Files\\news.jpg\n",
      "True ..\\Files\\photo.jpg\n",
      "True ..\\Files\\P_Galaxy_resized.jpg\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Detecting Faces in images\r\n",
    "This basically works by using **Cascades** which are some *XML* files that contains the info about the features that an image of a face contains. These features include (but aren't limited to) ratio of the shadows of the eyes and nose and lips. All these features (pixel intensities) are recorded in the XML file using some training samples.\r\n",
    "\r\n",
    "### Haar Cascades\r\n",
    "**So what is Haar Cascade?** It is an Object Detection Algorithm used to identify faces in an image or a real time video. The algorithm uses edge or line detection features proposed by Viola and Jones in their research paper “Rapid Object Detection using a Boosted Cascade of Simple Features” published in 2001. The algorithm is given a lot of positive images consisting of faces, and a lot of negative images not consisting of any face to train on them.\r\n",
    "\r\n",
    "For more details on haar cascades visit : https://towardsdatascience.com/face-detection-with-haar-cascade-727f68dafd08"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "What we'll do is load an image and then pass the model (the XML file) to python. And python will scan the image using `open CV` to search for faces using the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "#face_casc = cv2.CascadeClassifier(\"Img_n_Cam\\Files\\haarcascade_frontalface_default.xml\")\r\n",
    "face_casc = cv2.CascadeClassifier(r'..\\Files\\haarcascade_frontalface_default.xml')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we created a cascade classifier object, which we'll use to classify whether something is a face or not.\r\n",
    "\r\n",
    "One interesting thing is using grayscales image makes the classification much more simpler and accurate as there won't be too many unnecessary information in the image and the classification will be simpler and faster. \r\n",
    "Too many unnecessary info can lead `openCV` to miss out some features due to too much noise or take some random noise to be features pertaining to faces.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "image = cv2.imread(r\"..\\Files\\photo.jpg\") \r\n",
    "gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n",
    "cv2.imshow(\"Gray\",gray_img)\r\n",
    "cv2.waitKey(100)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So now we have the orignal colored image and a grayscales version of the image.\r\n",
    "\r\n",
    "Now we'll use **`detectMultiScale`** which will search for *cascadeClassifier* (the frontal face XML) in our image and will return the coordinates of the face in the image (The top left point in terms of pixel and the height and width of the face)\r\n",
    "\r\n",
    "**PARAMETERS:**\r\n",
    "\r\n",
    "**scaleFactor** – Parameter specifying how much the image size is reduced at each image scale.\r\n",
    "\r\n",
    "What this tells is to reduce the image size by a a certain factor so that larger objects can be recognized (the scan box remains of the same size)\r\n",
    "\r\n",
    "1.05 is a good possible value for this, which means you use a small step for resizing, i.e. reduce the size by 5%, you increase the chance of a matching size with the model for detection is found. This also means that the algorithm works slower since it is more thorough.\r\n",
    "\r\n",
    "**minNeighbors** - Parameter specifying how many neighbors each candidate rectangle should have to retain it.\r\n",
    "\r\n",
    "This parameter will affect the quality of the detected faces. Higher value results in fewer detections but with higher quality. 3~6 is a good value for it.\r\n",
    "\r\n",
    "**minSize** - Minimum possible object size. Objects smaller than that are ignored.\r\n",
    "\r\n",
    "**maxSize** – Maximum possible object size. Objects bigger than this are ignored.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "faces = face_casc.detectMultiScale(gray_img, \r\n",
    "scaleFactor = 1.05, \r\n",
    "minNeighbors = 5)\r\n",
    "\r\n",
    "print(faces)\r\n",
    "print(type(faces))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[157  84 379 379]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So the result is a *ndarray* which starts at $(157, 84)$ and is $349 X 349$\r\n",
    "\r\n",
    "Lets draw a rectangle arond the detected face"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "for x, y, w, h in faces:\r\n",
    "    image = cv2.rectangle(image, (x,y), (x+w, y+h), (255, 0, 0), 3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The parameters of **`cv2.rectangle`** are:\r\n",
    "- *The Image object*\r\n",
    "- The top left coordinate of the rectangle\r\n",
    "- The lower right coordinate of the rectangle\r\n",
    "- The color of the boundary of the rectangle\r\n",
    "- The width of the boundary"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "cv2.imshow(\"Image\",image)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()\r\n",
    "cv2.imwrite(r\"..\\Files\\Det_face.jpg\", image)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A more challenging detection problem is the *news picture*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "img_dif = cv2.imread(r\"..\\Files\\news.jpg\")\r\n",
    "img_gray = cv2.cvtColor(img_dif, cv2.COLOR_BGR2GRAY)\r\n",
    "cv2.imshow(\"GRAY\", img_gray)\r\n",
    "cv2.waitKey(200)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "faces = face_casc.detectMultiScale(img_gray, \r\n",
    "scaleFactor= 1.05,\r\n",
    "minNeighbors= 5)\r\n",
    "print(faces)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 42 220 108 108]\n",
      " [305 379  84  84]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "for x, y, w, h in faces:\r\n",
    "    img_dif = cv2.rectangle(img_dif, (x,y), (x+w, y+h), (255, 50, 0), 3)\r\n",
    "\r\n",
    "cv2.imshow(\"Result\", img_dif)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "See what happened. It wasn't able to detect the man's face and the face in the news paper in his hand. But it also miss-detected the hand of the man as a face"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "faces = face_casc.detectMultiScale(img_gray, \r\n",
    "scaleFactor= 1.1,\r\n",
    "minNeighbors= 5)\r\n",
    "print(faces)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 46 220 111 111]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "for x, y, w, h in faces:\r\n",
    "    img_dif = cv2.rectangle(img_dif, (x,y), (x+w, y+h), (255, 50, 0), 3)\r\n",
    "\r\n",
    "cv2.imshow(\"Result\", img_dif)\r\n",
    "cv2.waitKey(0)\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "So increasing the scale factor helped us to stop the classifier from classifying the hand as a face. But we couldn't detect the two faces."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "cv2.imwrite(r\"../Files/Det_diffimg.jpg\", img_dif)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "9da5a1eb768521143534bf09b996f0d525d45d2d4b488be6c4304e80c1815fea"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}